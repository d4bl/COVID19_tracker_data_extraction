{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data For Black Lives COVID-19 Webscraping\n",
    "\n",
    "\n",
    "<hr style=\"height:2pt\">\n",
    "\n",
    "We manually gathered data on states reporting COVID-19 cases and deaths by race. Below, we work on automatically scraping data from websites to update data daily."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Commented code is just FORMATTING \n",
    "import requests\n",
    "# from IPython.core.display import HTML\n",
    "# styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "# HTML(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages needed to run\n",
    "\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import email.utils as eut\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import re\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the webpage into a `requests` object with the following attributes: \n",
    "\n",
    "- `webpage.text`: attribute that is a string. We need this for input to BS\n",
    "- `webpage.status_code`: The `status_code` attribute returns the HTTP status code, which tells you whether your request was successful (200), or not\n",
    "- `webpage.content`: The `content` attribute gives you the raw HTML page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_soup(data_url):\n",
    "    \"\"\"\n",
    "    Converts string into beautiful soup object for parsing\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_url: string\n",
    "        website link\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data_soup: Beautifulsoup object\n",
    "        HMTL code from webpage\n",
    "    \"\"\"\n",
    "    data_page = requests.get(data_url)\n",
    "    if (data_page.status_code) == 200:\n",
    "        print('request successful')\n",
    "    else:\n",
    "        print('request failed for')\n",
    "\n",
    "    # Create a Beautiful Soup object\n",
    "    data_text = data_page.text\n",
    "    data_soup = BeautifulSoup(data_text, \"html.parser\")\n",
    "\n",
    "    # check to see a familiar HTML code\n",
    "#     print(data_soup.prettify()[:])\n",
    "    \n",
    "    return data_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json(url):\n",
    "    \"\"\"Simple function to return the parsed JSON from a web API.\"\"\"\n",
    "    # The next two lines can raise a requests.RequestException\n",
    "    r = requests.get(url) \n",
    "    r.raise_for_status()\n",
    "    # The next line can raise a ValueError\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_date(metadata_url):\n",
    "    \"\"\"For states using ESRI web services, the field metadata includes a timestamp. \n",
    "    This function fetches, extracts, and parses it, returning a datetime.date.\n",
    "    \"\"\"\n",
    "    metadata = get_json(metadata_url)\n",
    "    last_edit_ms = metadata['editingInfo']['lastEditDate']\n",
    "    # The next line can raise OverflowError\n",
    "    return datetime.date.fromtimestamp(last_edit_ms / 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionary corresponds to a state and has the following data:\n",
    "- `name`: the name of the state\n",
    "- `Date Published`: date webpage updated or published\n",
    "- `Total Cases`: total number of COVID-19 cases\n",
    "- `Total Deaths`: total number of COVID-19 deaths\n",
    "- `Pct Cases Black/AA`: percentage of cases that are Black/African American\n",
    "- `Pct Deaths Black/AA`: percentage of deaths that are Black/African American"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Georgia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://ga-covid19.ondemand.sas.com/docs/ga_covid_data.zip')\n",
    "# r.raise_for_status()\n",
    "# Since we are downloading a ZIP file whose CSVs are not date-tagged,\n",
    "# we might try use the HTTP Date header as an approximation\n",
    "r.headers['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Date header is in email date format; email.utils.parsedate can split this\n",
    "http_date_tuple = eut.parsedate(r.headers['Date'])\n",
    "http_date_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And taking a slice of the first three tuple elements, we can pass those to datetime.date\n",
    "http_date = datetime.date(*http_date_tuple[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = zipfile.ZipFile(BytesIO(r.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another date could be the last update of the demographics.csv file in the ZIP archive:\n",
    "info = z.getinfo('demographics.csv')\n",
    "info.date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That looks better. Let's use that\n",
    "zip_date = datetime.date(*info.date_time[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with z.open('demographics.csv') as cases:\n",
    "    data = pd.read_csv(cases)\n",
    "by_race = data[['race', 'Confirmed_Cases', 'Deaths']].groupby('race').sum()\n",
    "totals = by_race.sum(axis=0)\n",
    "GA = {\n",
    "    'name': 'Georgia',\n",
    "    'Date Published': zip_date,\n",
    "    'Total Cases': totals['Confirmed_Cases'],\n",
    "    'Total Deaths': totals['Deaths'],\n",
    "    'Pct Cases Black/AA': by_race.loc['AFRICAN-AMERICAN', 'Confirmed_Cases'] / totals['Confirmed_Cases'],\n",
    "    'Pct Deaths Black/AA': by_race.loc['AFRICAN-AMERICAN', 'Deaths'] / totals['Deaths'],\n",
    "}\n",
    "GA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delaware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_url = \"https://myhealthycommunity.dhss.delaware.gov/locations/state\"\n",
    "DE_soup = url_to_soup(DE_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Michigan\n",
    "MI = {\n",
    "     'name': 'Michigan'\n",
    "}\n",
    "MI_url = \"https://www.michigan.gov/coronavirus/0,9753,7-406-98163_98173---,00.html\"\n",
    "MI_soup = url_to_soup(MI_url)\n",
    "tables = MI_soup.find_all('table')\n",
    "for table in tables:\n",
    "    caption = table.find('caption')\n",
    "    if caption.string.find('Confirmed COVID-19 Case') >= 0:\n",
    "        m = re.search('updated (\\d+)/(\\d+)/(\\d+)', caption.string)\n",
    "        mon, day, year = tuple(map(int, m.groups()))\n",
    "        MI['Date Published'] = str(datetime.date(year, mon, day))\n",
    "        trs = table.find('tbody').find_all('tr')\n",
    "        tds = trs[-1].find_all('td')\n",
    "        total_cases = int(tds[1].string)\n",
    "        total_deaths = int(tds[2].string)\n",
    "    elif caption.string == 'Cases by Race':\n",
    "        for tr in table.find('tbody').find_all('tr'):\n",
    "            tds = tr.find_all('td')\n",
    "            if tds[0].string == 'Black or African American':\n",
    "                aa_cases = int(tds[1].string.strip('% '))\n",
    "                aa_deaths = int(tds[2].string.strip('% '))\n",
    "MI['Total Cases'] = total_cases\n",
    "MI['Total Deaths'] = total_deaths\n",
    "MI['Pct Cases Black/AA'] = aa_cases / total_cases\n",
    "MI['Pct Deaths Black/AA'] = aa_deaths / total_deaths\n",
    "MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minnesota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MN_url = \"https://www.health.state.mn.us/diseases/coronavirus/situation.html#raceeth1\"\n",
    "MN_soup = url_to_soup(MN_url)\n",
    "\n",
    "# find date and total number of cases and deaths\n",
    "counter = 0\n",
    "num_cases = ''\n",
    "num_deaths = ''\n",
    "for strong_tag in MN_soup.find_all('strong'):\n",
    "    this_string = strong_tag.text, strong_tag.next_sibling\n",
    "    this_heading = strong_tag.text\n",
    "    if counter == 0:\n",
    "        date_text = strong_tag.text.strip('.')[11:]\n",
    "    if this_heading == 'Total positive: ':\n",
    "        num_cases = strong_tag.next_sibling\n",
    "    if this_heading == 'Deaths: ':\n",
    "        num_deaths = strong_tag.next_sibling\n",
    "    counter += 1\n",
    "    \n",
    "date_time_obj = datetime.datetime.strptime(date_text, \"%B %d, %Y\")\n",
    "date_formatted = date_time_obj.strftime(\"%m/%d/%Y\")\n",
    "print('Date:', date_formatted)\n",
    "print('Number Cases:', num_cases)\n",
    "print('Number Deaths:', num_deaths)\n",
    "\n",
    "# find number of Black/AA cases and deaths\n",
    "table = MN_soup.find(\"div\", attrs={\"id\":\"raceeth\"})\n",
    "counter = 0\n",
    "pct_cases = ''\n",
    "pct_deaths = ''\n",
    "for th in table.find_all('th'):\n",
    "    text = th.text\n",
    "#     print(th.next_sibling)\n",
    "    if text == \"Black\":\n",
    "#         print(table.find_all('td'))\n",
    "        pct_cases = table.find_all('td')[counter-2].text.strip('%')\n",
    "        pct_deaths = table.find_all('td')[counter-1].text.strip('%')\n",
    "    counter += 1\n",
    "\n",
    "print('Pct Cases Black/AA:', pct_cases)\n",
    "print('Pct Deaths Black/AA:', pct_deaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# North Carolina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NC_url = \"https://www.ncdhhs.gov/divisions/public-health/covid19/covid-19-nc-case-count#by-race-ethnicity\"\n",
    "NC_soup = url_to_soup(NC_url)\n",
    "\n",
    "# find date and total number of cases and deaths\n",
    "date_text = NC_soup.find(\"div\", attrs={\"class\":\"field-item\"}).p.text[50:]\n",
    "date_time_obj = datetime.datetime.strptime(date_text, \"%B %d, %Y. \")\n",
    "date_formatted = date_time_obj.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "\n",
    "field_item = NC_soup.find(\"div\", attrs={\"class\":\"field-item\"})\n",
    "# num_cases = field_item.findAll(\"tr\")[1].td.text\n",
    "items = field_item.findAll(\"tr\")[1]\n",
    "num_cases = items.findAll(\"td\")[1].text\n",
    "num_deaths = items.findAll(\"td\")[0].text\n",
    "\n",
    "print('Date:', date_formatted)\n",
    "print('Number Cases:', num_cases)\n",
    "print('Number Deaths:', num_deaths)\n",
    "\n",
    "# find number of Black/AA cases and deaths\n",
    "tables = NC_soup.findAll(\"table\")\n",
    "race_data = tables[4]\n",
    "num_race_cases = race_data.findAll(\"td\")[6]\n",
    "num_race_deaths = race_data.findAll(\"td\")[8]\n",
    "pct_cases = race_data.findAll(\"td\")[22].text.strip('%')\n",
    "pct_deaths = race_data.findAll(\"td\")[24].text.strip('%')\n",
    "\n",
    "print('Pct Cases Black/AA:', pct_cases)\n",
    "print('Pct Deaths Black/AA:', pct_deaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texas - Bexar County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_Bexar = {\n",
    "    'name': 'Texas - Bexar County',\n",
    "}\n",
    "try:\n",
    "    # Start by fetching the metadata to get the likey timestamp\n",
    "    md_date = get_metadata_date('https://services.arcgis.com/g1fRTDLeMgspWrYp/arcgis/rest/services/vRaceEthnicity/FeatureServer/0?f=json')\n",
    "    TX_Bexar['Date Published'] = str(md_date)\n",
    "\n",
    "    # Next get the cumulative case and death counts\n",
    "    total = get_json('https://services.arcgis.com/g1fRTDLeMgspWrYp/arcgis/rest/services/vDateCOVID19_Tracker_Public/FeatureServer/0/query?f=json&where=Date%20BETWEEN%20timestamp%20%272020-05-07%2005%3A00%3A00%27%20AND%20timestamp%20%272020-05-08%2004%3A59%3A59%27&returnGeometry=false&spatialRel=esriSpatialRelIntersects&outFields=*&resultOffset=0&resultRecordCount=50&resultType=standard&cacheHint=true')\n",
    "    TX_Bexar['Total Cases'] = total['features'][0]['attributes']['ReportedCum']\n",
    "    TX_Bexar['Total Deaths'] = total['features'][0]['attributes']['DeathsCum']\n",
    "\n",
    "    # And finally the race/ethnicity breakdowns\n",
    "    data = get_json('https://services.arcgis.com/g1fRTDLeMgspWrYp/arcgis/rest/services/vRaceEthnicity/FeatureServer/0/query?f=json&where=1%3D1&returnGeometry=false&spatialRel=esriSpatialRelIntersects&outFields=*&resultOffset=0&resultRecordCount=20&resultType=standard&cacheHint=true')\n",
    "    for feature in data.get('features', []):\n",
    "        if feature['attributes']['RaceEthnicity'] == 'Black':\n",
    "            TX_Bexar['Pct Cases Black/AA'] = feature['attributes']['CasesConfirmed'] / TX_Bexar['Total Cases']\n",
    "            TX_Bexar['Pct Deaths Black/AA'] = feature['attributes']['Deaths'] / TX_Bexar['Total Deaths']\n",
    "            break\n",
    "    if 'Pct Cases Black/AA' not in TX_Bexar:\n",
    "        raise ValueError('No data found for Black RaceEthnicity category')\n",
    "\n",
    "except OverflowError as e:\n",
    "    print(\"Error processing last update timstamp for TX_Bexar\")\n",
    "except ValueError as e:\n",
    "    print(\"Error processing data for TX_Bexar\", e)\n",
    "except requests.RequestException as e:\n",
    "    print(\"Error retrieving URL for TX_Bexar:\", e.request.url)\n",
    "TX_Bexar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WI - Milwaukee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WI_Milwaukee = {\n",
    "    'name': 'Wisconsin - Milwaukee',\n",
    "}\n",
    "try:\n",
    "    # Get the timestamp\n",
    "    cases_date = get_metadata_date('https://services5.arcgis.com/8Q02ELWlq5TYUASS/arcgis/rest/services/Cases_View/FeatureServer/0?f=json')\n",
    "    deaths_date = get_metadata_date('https://services5.arcgis.com/8Q02ELWlq5TYUASS/arcgis/rest/services/Deaths_View1/FeatureServer/0?f=json')\n",
    "    if cases_date != deaths_date:\n",
    "        print('Unexpected mismath between cases and deaths metadata dates:', cases_date, '!=', deaths_date)\n",
    "    WI_Milwaukee['Date Published'] = str(cases_date)\n",
    "    \n",
    "    cases_total = get_json('https://services5.arcgis.com/8Q02ELWlq5TYUASS/arcgis/rest/services/Cases_View/FeatureServer/0/query?f=json&where=1%3D1&returnGeometry=false&spatialRel=esriSpatialRelIntersects&outFields=*&outStatistics=%5B%7B%22statisticType%22%3A%22count%22%2C%22onStatisticField%22%3A%22ObjectId%22%2C%22outStatisticFieldName%22%3A%22value%22%7D%5D&resultType=standard&cacheHint=true')\n",
    "    WI_Milwaukee['Total Cases'] = cases_total['features'][0]['attributes']['value']\n",
    "    deaths_total = get_json('https://services5.arcgis.com/8Q02ELWlq5TYUASS/arcgis/rest/services/Deaths_View1/FeatureServer/0/query?f=json&where=1%3D1&returnGeometry=false&spatialRel=esriSpatialRelIntersects&outFields=*&outStatistics=%5B%7B%22statisticType%22%3A%22count%22%2C%22onStatisticField%22%3A%22ObjectId%22%2C%22outStatisticFieldName%22%3A%22value%22%7D%5D&resultType=standard&cacheHint=true')\n",
    "    WI_Milwaukee['Total Deaths'] = deaths_total['features'][0]['attributes']['value']\n",
    "    \n",
    "    cases_by_race = get_json('https://services5.arcgis.com/8Q02ELWlq5TYUASS/arcgis/rest/services/Cases_View/FeatureServer/0/query?f=json&where=Race_Eth%20NOT%20LIKE%20%27%25%23N%2FA%27&returnGeometry=false&spatialRel=esriSpatialRelIntersects&outFields=*&groupByFieldsForStatistics=Race_Eth&orderByFields=value%20desc&outStatistics=%5B%7B%22statisticType%22%3A%22count%22%2C%22onStatisticField%22%3A%22ObjectId%22%2C%22outStatisticFieldName%22%3A%22value%22%7D%5D&resultType=standard&cacheHint=true')\n",
    "    for feature in cases_by_race['features']:\n",
    "        if feature['attributes']['Race_Eth'] == 'Black Alone':\n",
    "            WI_Milwaukee['Pct Cases Black/AA'] = feature['attributes']['value'] / WI_Milwaukee['Total Cases']\n",
    "            break\n",
    "\n",
    "    deaths_by_race = get_json('https://services5.arcgis.com/8Q02ELWlq5TYUASS/arcgis/rest/services/Deaths_View1/FeatureServer/0/query?f=json&where=1%3D1&returnGeometry=false&spatialRel=esriSpatialRelIntersects&outFields=*&groupByFieldsForStatistics=Race_Eth&orderByFields=value%20desc&outStatistics=%5B%7B%22statisticType%22%3A%22count%22%2C%22onStatisticField%22%3A%22ObjectId%22%2C%22outStatisticFieldName%22%3A%22value%22%7D%5D&resultType=standard&cacheHint=true')\n",
    "    for feature in deaths_by_race['features']:\n",
    "        if feature['attributes']['Race_Eth'] == 'Black Alone':\n",
    "            WI_Milwaukee['Pct Deaths Black/AA'] = feature['attributes']['value'] / WI_Milwaukee['Total Deaths']\n",
    "            break\n",
    "except OverflowError as e:\n",
    "    print(\"Error processing last update timstamp for WI_Milwaukee\")\n",
    "except ValueError as e:\n",
    "    print(\"Error processing data for WI_Milwaukee\", e)\n",
    "except requests.RequestException as e:\n",
    "    print(\"Error retrieving URL for WI_Milwaukee:\", e.request.url)\n",
    "WI_Milwaukee"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
